# local-llm
## prepare local llm environment
### Install ollama
https://ollama.com/download

### Install model
```bash
ollama run {model_name e.g. "llama3"}
```
